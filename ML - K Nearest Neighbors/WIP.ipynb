{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances, cosine_distances\n",
    "from src.load_json_data import load_json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs = load_json_data(os.path.join('data', 'blobs.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "\n",
    "def euclidean_distance(v, w):\n",
    "    \"\"\"Returns the Euclidean distance between two vectors\"\"\"\n",
    "\n",
    "    return math.sqrt(sum([(v[ii]-w[ii])**2 for ii in range(len(v))]))\n",
    "\n",
    "def manhattan_distance(v, w):\n",
    "    \"\"\"Returns the Manhattan distance between two vectors\"\"\"\n",
    "\n",
    "    return sum([abs(v[ii]-w[ii]) for ii in range(len(v))])\n",
    "\n",
    "def euclidean_distances(X, Y):\n",
    "    \"\"\"Compute pairwise Euclidean distance between the rows of two matrices X (shape MxK) \n",
    "    and Y (shape NxK). The output of this function is a matrix of shape MxN containing\n",
    "    the Euclidean distance between two rows.\n",
    "    \n",
    "    Arguments:\n",
    "        X {np.ndarray} -- First matrix, containing M examples with K features each.\n",
    "        Y {np.ndarray} -- Second matrix, containing N examples with K features each.\n",
    "\n",
    "    Returns:\n",
    "        D {np.ndarray}: MxN matrix with Euclidean distances between rows of X and rows of Y.\n",
    "    \"\"\"\n",
    "    \n",
    "    result = np.ndarray((X.shape[0], Y.shape[0]))\n",
    "    \n",
    "    for ii in range(X.shape[0]):\n",
    "        for kk in range(Y.shape[0]):\n",
    "            \n",
    "            result[ii,kk] = euclidean_distance(X[ii], Y[kk])\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def manhattan_distances(X, Y):\n",
    "    \"\"\"Compute pairwise Manhattan distance between the rows of two matrices X (shape MxK) \n",
    "    and Y (shape NxK). The output of this function is a matrix of shape MxN containing\n",
    "    the Manhattan distance between two rows.\n",
    "    \n",
    "    Arguments:\n",
    "        X {np.ndarray} -- First matrix, containing M examples with K features each.\n",
    "        Y {np.ndarray} -- Second matrix, containing N examples with K features each.\n",
    "\n",
    "    Returns:\n",
    "        D {np.ndarray}: MxN matrix with Manhattan distances between rows of X and rows of Y.\n",
    "    \"\"\"\n",
    "    result = np.ndarray((X.shape[0], Y.shape[0]))\n",
    "    \n",
    "    for ii in range(X.shape[0]):\n",
    "        for kk in range(Y.shape[0]):\n",
    "            \n",
    "            result[ii,kk] = manhattan_distance(X[ii], Y[kk])\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_blobs, y_blobs = load_json_data(os.path.join('data', 'blobs.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "class KNearestNeighbor():    \n",
    "    def __init__(self, n_neighbors, distance_measure='euclidean', aggregator='mode'):\n",
    "        \"\"\"\n",
    "        K-Nearest Neighbor is a straightforward algorithm that can be highly\n",
    "        effective. Training time is...well...is there any training? At test time, labels for\n",
    "        new points are predicted by comparing them to the nearest neighbors in the\n",
    "        training data.\n",
    "\n",
    "        ```distance_measure``` lets you switch between which distance measure you will\n",
    "        use to compare data points. The behavior is as follows:\n",
    "\n",
    "        If 'euclidean', use euclidean_distances, if 'manhattan', use manhattan_distances.\n",
    "\n",
    "        ```aggregator``` lets you alter how a label is predicted for a data point based \n",
    "        on its neighbors. If it's set to `mean`, it is the mean of the labels of the\n",
    "        neighbors. If it's set to `mode`, it is the mode of the labels of the neighbors.\n",
    "        If it is set to median, it is the median of the labels of the neighbors. If the\n",
    "        number of dimensions returned in the label is more than 1, the aggregator is\n",
    "        applied to each dimension independently. For example, if the labels of 3 \n",
    "        closest neighbors are:\n",
    "            [\n",
    "                [1, 2, 3], \n",
    "                [2, 3, 4], \n",
    "                [3, 4, 5]\n",
    "            ] \n",
    "        And the aggregator is 'mean', applied along each dimension, this will return for \n",
    "        that point:\n",
    "            [\n",
    "                [2, 3, 4]\n",
    "            ]\n",
    "\n",
    "        Arguments:\n",
    "            n_neighbors {int} -- Number of neighbors to use for prediction.\n",
    "            distance_measure {str} -- Which distance measure to use. Can be one of\n",
    "                'euclidean' or 'manhattan'. This is the distance measure\n",
    "                that will be used to compare features to produce labels. \n",
    "            aggregator {str} -- How to aggregate a label across the `n_neighbors` nearest\n",
    "                neighbors. Can be one of 'mode', 'mean', or 'median'.\n",
    "        \"\"\"\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.distance_measure = distance_measure\n",
    "        self.aggregator = aggregator\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, features, targets):\n",
    "        \"\"\"Fit features, a numpy array of size (n_samples, n_features). For a KNN, this\n",
    "        function should store the features and corresponding targets in class \n",
    "        variables that can be accessed in the `predict` function. Note that targets can\n",
    "        be multidimensional! \n",
    "        \n",
    "        Arguments:\n",
    "            features {np.ndarray} -- Features of each data point, shape of (n_samples,\n",
    "                n_features).\n",
    "            targets {[type]} -- Target labels for each data point, shape of (n_samples, \n",
    "                n_dimensions).\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "\n",
    "    def predict(self, features, ignore_first=False):\n",
    "        \"\"\"Predict from features, a numpy array of size (n_samples, n_features) Use the\n",
    "        training data to predict labels on the test features. For each testing sample, compare it\n",
    "        to the training samples. Look at the self.n_neighbors closest samples to the \n",
    "        test sample by comparing their feature vectors. The label for the test sample\n",
    "        is the determined by aggregating the K nearest neighbors in the training data.\n",
    "\n",
    "        Note that when using KNN for imputation, the predicted labels are the imputed testing data\n",
    "        and the shape is (n_samples, n_features).\n",
    "\n",
    "        Arguments:\n",
    "            features {np.ndarray} -- Features of each data point, shape of (n_samples,\n",
    "                n_features).\n",
    "            ignore_first {bool} -- If this is True, then we ignore the closest point\n",
    "                when doing the aggregation. This is used for collaborative\n",
    "                filtering, where the closest point is itself and thus is not a neighbor. \n",
    "                In this case, we would use 1:(n_neighbors + 1).\n",
    "\n",
    "        Returns:\n",
    "            labels {np.ndarray} -- Labels for each data point, of shape (n_samples,\n",
    "                n_dimensions). This n_dimensions should be the same as n_dimensions of targets in fit function.\n",
    "        \"\"\"\n",
    "        print(features)\n",
    "        distance_types = dict()\n",
    "        distance_types['euclidean'] = euclidean_distances\n",
    "        distance_types['manhattan'] = manhattan_distances\n",
    "        \n",
    "        # A single row are all the distances from a vector in the training data to each vector in the new data\n",
    "        # A single column are all the distances from a vector in the new data to a vector in the training data\n",
    "        distances = distance_types[self.distance_measure](self.features, features)\n",
    "        print(self.features)\n",
    "        print(distances)\n",
    "#         labels = np.ndarray((features.shape[0], self.targets.shape[1]))\n",
    "        labels = list()\n",
    "        \n",
    "        for ii in range(features.shape[0]):\n",
    "            \n",
    "            # Take all the distances from the ii-th vector in the new data to each of the vectors in the training data\n",
    "            # enumerate them in tuples (in order to memorize their position in the data and use it to retrieve the appropriate labels from self.targets )\n",
    "            # and sort them in ascending order by distance\n",
    "            # take only the self.n_neighbors top tuples (corresponding to the nearest neighbours)\n",
    "            lowest_distances = sorted(list(enumerate(distances[:,ii])), key = lambda x: x[1])[ignore_first:self.n_neighbors+ignore_first]\n",
    "            lowest_indices = [distance_tuple[0] for distance_tuple in lowest_distances ]\n",
    "            \n",
    "            lowest_labels = self.targets[lowest_indices,]\n",
    "            \n",
    "            print(\"LOWEST_DISTANCES\")\n",
    "            print(lowest_distances)\n",
    "            print(\"LOWEST INDICES\")\n",
    "            print(lowest_indices)\n",
    "            print(\"TARGETS\")\n",
    "            print(self.targets)\n",
    "            print(\"LOWEST LABELS \")\n",
    "            print(lowest_labels)\n",
    "            \n",
    "            if self.aggregator == 'median':\n",
    "                this_vector_labels = np.median(lowest_labels, axis=0)\n",
    "                \n",
    "            if self.aggregator == 'mean':\n",
    "                this_vector_labels = np.mean(lowest_labels, axis=0)\n",
    "                \n",
    "            if self.aggregator == 'mode':\n",
    "                print(\"SELF.TARGETS.SHAPE: \", self.targets.reshape(-1,1).shape)\n",
    "                print(\"SELF.TARGETS.SHAPE[1]: \", self.targets.reshape(-1,1).shape[1])\n",
    "#                 this_vector_labels = [statistics.mode(lowest_labels[:, kk]) for kk in range(self.targets.reshape(-1,1).shape[0])]\n",
    "                if lowest_labels.ndim != 1:\n",
    "                    this_vector_labels = list()\n",
    "                    for kk in range(lowest_labels.shape[1]):\n",
    "                        this_vector_labels.append(statistics.mode([row[kk] for row in lowest_labels]))\n",
    "                else:\n",
    "                    this_vector_labels = statistics.mode(lowest_labels)\n",
    "    \n",
    "\n",
    "            print(f'PREDICTION for {ii}-th vector is: {this_vector_labels}')    \n",
    "            print(this_vector_labels)\n",
    "            labels.append(this_vector_labels)\n",
    "        \n",
    "        return np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]])\n",
    "y_train = np.array([[5,8],[5,10], [7,10], [6,9]])\n",
    "\n",
    "X_test = np.array([[3,6,8], [3,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNearestNeighbor(3, distance_measure='manhattan' )# ,aggregator='median'\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array([[10, 15],\n",
    "#         [13,17]]).reshape(1,-1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 6 8]\n",
      " [3 5 6]]\n",
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "[[11.  8.]\n",
      " [ 4.  1.]\n",
      " [ 7. 10.]\n",
      " [16. 19.]]\n",
      "LOWEST_DISTANCES\n",
      "[(1, 4.0), (2, 7.0), (0, 11.0)]\n",
      "LOWEST INDICES\n",
      "[1, 2, 0]\n",
      "TARGETS\n",
      "[[ 5  8]\n",
      " [ 5 10]\n",
      " [ 7 10]\n",
      " [ 6  9]]\n",
      "LOWEST LABELS \n",
      "[[ 5 10]\n",
      " [ 7 10]\n",
      " [ 5  8]]\n",
      "SELF.TARGETS.SHAPE:  (8, 1)\n",
      "SELF.TARGETS.SHAPE[1]:  1\n",
      "PREDICTION for 0-th vector is: [5, 10]\n",
      "[5, 10]\n",
      "LOWEST_DISTANCES\n",
      "[(1, 1.0), (0, 8.0), (2, 10.0)]\n",
      "LOWEST INDICES\n",
      "[1, 0, 2]\n",
      "TARGETS\n",
      "[[ 5  8]\n",
      " [ 5 10]\n",
      " [ 7 10]\n",
      " [ 6  9]]\n",
      "LOWEST LABELS \n",
      "[[ 5 10]\n",
      " [ 5  8]\n",
      " [ 7 10]]\n",
      "SELF.TARGETS.SHAPE:  (8, 1)\n",
      "SELF.TARGETS.SHAPE[1]:  1\n",
      "PREDICTION for 1-th vector is: [5, 10]\n",
      "[5, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5, 10],\n",
       "       [ 5, 10]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(X_test) #ignore_first=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "statistics.mode([1,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15, 20],\n",
       "       [ 7, 13],\n",
       "       [ 7, 13]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([[15 ,20],\n",
    " [7 ,13], [7 ,13]])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15 20]\n",
      "[ 7 13]\n",
      "[ 7 13]\n"
     ]
    }
   ],
   "source": [
    "for row in arr:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 20])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.array([15 ,20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 13]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if arr.ndim != 1:\n",
    "    this_vector_labels = list()\n",
    "    for kk in range(arr.shape[1]):\n",
    "        this_vector_labels.append(statistics.mode([row[kk] for row in arr]))\n",
    "        \n",
    "this_vector_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw2-knn",
   "language": "python",
   "name": "hw2-knn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
